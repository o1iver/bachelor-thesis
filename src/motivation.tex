\chapter{Motivation}
\label{motivation}

Engineers successfully model complex physical systems using graphical modelling software. The visual nature of graphical models allows an easier transfer of process expertise to a computer representation of complex systems. Nonetheless these tools have drawbacks. Rule based representations of dynamic systems are hard to solve. Complex differential equations require intelligent solvers and computing power.

Contrastingly, dynamic systems modelled as Markov Processes provide a simply solvable, yet extremely unintuitive representation. Non-trivial Markov Decision Processes and even more so Partially Observable Markov Decision Processes cannot be designed using first-principle approaches such as those used to construct most graphical differential-equation-based models. However, once represented as such, Markov Processes are an extremely powerful tool for non-myopic optimization.

The motivation of this work is to provide a tool that can transform models produced by engineers using graphical modelling tools into a system representation that can more easily be used for non-myopic optimization, without the need for complex solvers and raw computing power. A successful automatic transformation tool would allow engineers to use the tools best suited to them, whilst still allowing for the non-myopic optimization of complex dynamic systems without the need for advanced and computationally-costly mathematical solvers. The following two paragraphs quickly present two different use cases of this representational transformation.

The first example is of an extremely complex non-linear dynamic system: a Waste-to-Energy plant. Waste-to-Energy plants provide an interesting optimization problem. The complex intertial incineration process must be managed optimally by taking into account two different cost/reward sources, the time- and temperature-dependent district heating system and the extremely dynamic electricity market. Using Partially Observable Markov Decision Processes for the optimization of such a complex system would provide two main advantages. Firstly, the non-myopic nature of MDP- and POMDP-based optimization allows for a farther optimization horizon, especially useful for the optimization of such an intertial plant. Secondly, the decoupling of the reward model from the system dynamics permits dynamic on-line optimization, that constantly takes into account changing market conditions, without re-simulating the complex dynamic system.

The second example is of a much simpler dynamic system: a window blind controller. The number of windows in a house and the costs do not allow for expensive simulation-software-based model predictive control systems. Optimization using Markov Decision Processes may, on the other hand, be possible using cheap embedded devices with vector processors. Optimization using Markov Decision Processes only requires matrix and vector multiplications, making optimizatin on cheap specialized embedded devices possible. Using an expensive graphical modelling tool, such as Simulink, engineers could model the window blind system and its associated reward system, then transform the system into a Markov Decision Process and finally provide thousands of homes with cheap and \textit{smart} window blind controllers.


